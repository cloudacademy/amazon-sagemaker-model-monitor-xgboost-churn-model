{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring and Analyzing Data Quality for XGBoost Churn Models With Amazon SageMaker Model Monitor\n",
    "\n",
    "This notebook demonstrates how to use Amazon SageMaker Model Monitor to track and analyze the performance of a deployed machine learning model in real-time. You will be working with a pre-trained XGBoost model for customer churn prediction, demonstrating how SageMaker Model Monitor can automatically detect data quality issues that might affect your model's performance in production.\n",
    "\n",
    "To use this notebook:\n",
    "\n",
    "- Clone the repository containing this notebook and associated files.\n",
    "- Open the notebook in SageMaker Studio or a SageMaker Notebook Instance.\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "1. Set up a SageMaker environment for model monitoring\n",
    "2. Deploy a model to a SageMaker endpoint with data capture enabled\n",
    "3. Create a baseline for model monitoring\n",
    "4. Implement a monitoring schedule for a deployed model\n",
    "5. Analyze monitoring results and detect data quality issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up the SageMaker Environment\n",
    "\n",
    "Initializes the SageMaker session, sets up S3 buckets, and defines key variables for the model monitoring project.\n",
    "\n",
    "**Actions:**\n",
    "1. Import necessary libraries\n",
    "2. Create a SageMaker session\n",
    "3. Get the execution role\n",
    "4. Set up S3 bucket and prefixes for data capture and reports\n",
    "5. Print out the paths for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role, session\n",
    "\n",
    "sm_session = sagemaker.Session()\n",
    "region = sm_session.boto_region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "print(\"Role ARN: {}\".format(role))\n",
    "\n",
    "bucket = sm_session.default_bucket()\n",
    "print(\"Demo Bucket: {}\".format(bucket))\n",
    "prefix = \"sagemaker/DEMO-ModelMonitor\"\n",
    "\n",
    "data_capture_prefix = \"{}/datacapture\".format(prefix)\n",
    "s3_capture_upload_path = \"s3://{}/{}\".format(bucket, data_capture_prefix)\n",
    "reports_prefix = \"{}/reports\".format(prefix)\n",
    "s3_report_path = \"s3://{}/{}\".format(bucket, reports_prefix)\n",
    "\n",
    "print(\"Capture path: {}\".format(s3_capture_upload_path))\n",
    "print(\"Report path: {}\".format(s3_report_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the Pre-trained Model\n",
    "\n",
    "Upload the pre-trained XGBoost model to Amazon S3. SageMaker requires the model file to be accessible in S3 for deployment.\n",
    "\n",
    "**Actions:**\n",
    "1. Open the pre-trained model file\n",
    "2. Define the S3 key for the model\n",
    "3. Upload the model to the S3 bucket\n",
    "4. Print a confirmation message\n",
    "\n",
    "This code assumes that the \"xgb-churn-prediction-model.tar.gz\" file is present in the \"model\" directory of your repository. If you've cloned the repository correctly, this file should already be in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = open(\"model/xgb-churn-prediction-model.tar.gz\", \"rb\")\n",
    "s3_key = os.path.join(prefix, \"xgb-churn-prediction-model.tar.gz\")\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(s3_key).upload_fileobj(model_file)\n",
    "\n",
    "print(f\"Model uploaded successfully to s3://{bucket}/{s3_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a SageMaker Model Object\n",
    "\n",
    "Create a SageMaker model object using the uploaded pre-trained model.\n",
    "\n",
    "**Actions:**\n",
    "1. Generate a unique model name\n",
    "2. Construct the S3 URL for the uploaded model\n",
    "3. Retrieve the Docker image URI for XGBoost\n",
    "4. Create a SageMaker Model object\n",
    "5. Print model details for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "model_name = \"DEMO-xgb-churn-pred-model-monitor-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(f\"Model name: {model_name}\")\n",
    "\n",
    "model_url = \"https://{}.s3-{}.amazonaws.com/{}/xgb-churn-prediction-model.tar.gz\".format(\n",
    "    bucket, region, prefix\n",
    ")\n",
    "print(f\"Model URL: {model_url}\")\n",
    "\n",
    "image_uri = retrieve(\"xgboost\", region, \"0.90-1\")\n",
    "print(f\"Docker image URI: {image_uri}\")\n",
    "\n",
    "model = Model(image_uri=image_uri, model_data=model_url, role=role)\n",
    "print(\"SageMaker Model object created successfully\")\n",
    "print(f\"Model data location: {model.model_data}\")\n",
    "print(f\"Model role ARN: {model.role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Model with Data Capture\n",
    "\n",
    "Deploy the SageMaker model to an endpoint with data capture enabled for model monitoring.\n",
    "\n",
    "**Actions:**\n",
    "1. Generate a unique endpoint name\n",
    "2. Configure data capture settings\n",
    "3. Deploy the model to a SageMaker endpoint\n",
    "4. Print the endpoint name for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "endpoint_name = \"DEMO-xgb-churn-pred-model-monitor-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"EndpointName={}\".format(endpoint_name))\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True, sampling_percentage=100, destination_s3_uri=s3_capture_upload_path\n",
    ")\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    data_capture_config=data_capture_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Test Data and Send Test Traffic to the Endpoint\n",
    "\n",
    "Prepare a sample of test data and sends it to the deployed model endpoint to generate inference data for monitoring.\n",
    "\n",
    "**Actions:**\n",
    "1. Create a Predictor object for the deployed endpoint\n",
    "2. Prepare a subset of test data\n",
    "3. Send test data to the endpoint\n",
    "4. Print confirmation message\n",
    "\n",
    "This code assumes that the \"test-dataset-input-cols.csv\" and \"test_sample.csv\" files are present in the \"test_data\" directory of your repository. If you've cloned the repository correctly, this file should already be in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "import time\n",
    "\n",
    "predictor = Predictor(endpoint_name=endpoint_name, serializer=CSVSerializer())\n",
    "\n",
    "# Get a subset of test data for a quick test\n",
    "!head -180 test_data/test-dataset-input-cols.csv > test_data/test_sample.csv\n",
    "print(\"Sending test traffic to the endpoint {}. \\nPlease wait...\".format(endpoint_name))\n",
    "\n",
    "with open(\"test_data/test_sample.csv\", \"r\") as f:\n",
    "    for row in f:\n",
    "        payload = row.rstrip(\"\\n\")\n",
    "        response = predictor.predict(data=payload)\n",
    "        time.sleep(1)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Data Capture\n",
    "\n",
    "Verifiy that data is being captured correctly from the model endpoint.\n",
    "\n",
    "**Actions:**\n",
    "1. Set up an S3 client\n",
    "2. List objects in the data capture S3 prefix\n",
    "3. Print the captured files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.Session().client(\"s3\")\n",
    "current_endpoint_capture_prefix = \"{}/{}\".format(data_capture_prefix, endpoint_name)\n",
    "result = s3_client.list_objects(Bucket=bucket, Prefix=current_endpoint_capture_prefix)\n",
    "capture_files = [capture_file.get(\"Key\") for capture_file in result.get(\"Contents\")]\n",
    "print(\"Found Capture Files:\")\n",
    "print(\"\\n \".join(capture_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Captured Data\n",
    "\n",
    "Retrieve and displays a sample of the captured data for inspection.\n",
    "\n",
    "**Actions:**\n",
    "1. Define a function to get the body of an S3 object\n",
    "2. Retrieve the content of the latest capture file\n",
    "3. Print a portion of the captured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obj_body(obj_key):\n",
    "    return s3_client.get_object(Bucket=bucket, Key=obj_key).get(\"Body\").read().decode(\"utf-8\")\n",
    "\n",
    "capture_file = get_obj_body(capture_files[-1])\n",
    "print(capture_file[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine a Single Captured Record\n",
    "\n",
    "Parse and display a single record from the captured data to understand its structure in detail.\n",
    "\n",
    "**Actions:**\n",
    "1. Import the json module\n",
    "2. Extract the first record from the captured data\n",
    "3. Parse the record as JSON\n",
    "4. Print the formatted JSON record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(json.loads(capture_file.split(\"\\n\")[0]), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Baseline Data for Model Monitoring\n",
    "\n",
    "Prepares the environment for creating a baseline against which future data will be compared for model monitoring.\n",
    "\n",
    "**Actions:**\n",
    "1. Define S3 prefixes for baseline data and results\n",
    "2. Construct S3 URIs for baseline data and results\n",
    "3. Print the URIs for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_prefix = prefix + \"/baselining\"\n",
    "baseline_data_prefix = baseline_prefix + \"/data\"\n",
    "baseline_results_prefix = baseline_prefix + \"/results\"\n",
    "\n",
    "baseline_data_uri = \"s3://{}/{}\".format(bucket, baseline_data_prefix)\n",
    "baseline_results_uri = \"s3://{}/{}\".format(bucket, baseline_results_prefix)\n",
    "print(\"Baseline data uri: {}\".format(baseline_data_uri))\n",
    "print(\"Baseline results uri: {}\".format(baseline_results_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Baseline Data to S3\n",
    "\n",
    "Upload the training dataset to S3, which will serve as the baseline for model monitoring.\n",
    "\n",
    "**Actions:**\n",
    "1. Open the training dataset file\n",
    "2. Define the S3 key for the baseline data\n",
    "3. Upload the file to the S3 bucket\n",
    "4. Print confirmation message with the S3 path\n",
    "\n",
    "This step assumes that the file \"training-dataset-with-header.csv\" is present in the \"test_data\" directory of your repository. If you've cloned the repository correctly, this file should already be in place. Ensure that the file exists before running this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_file = open(\"test_data/training-dataset-with-header.csv\", \"rb\")\n",
    "s3_key = os.path.join(baseline_prefix, \"data\", \"training-dataset-with-header.csv\")\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(s3_key).upload_fileobj(training_data_file)\n",
    "\n",
    "print(f\"Training data uploaded to s3://{bucket}/{s3_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Configure Default Model Monitor\n",
    "\n",
    "Set up the default model monitor with the baseline data, which will be used to detect deviations in future data.\n",
    "\n",
    "**Actions:**\n",
    "1. Import necessary modules from SageMaker Model Monitor\n",
    "2. Create a DefaultModelMonitor instance\n",
    "3. Suggest a baseline using the uploaded training data\n",
    "4. Wait for the baseline suggestion process to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "my_default_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")\n",
    "\n",
    "my_default_monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_data_uri + \"/training-dataset-with-header.csv\",\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Baseline Results\n",
    "\n",
    "Retrieve and display the files generated during the baseline creation process.\n",
    "\n",
    "**Actions:**\n",
    "1. Set up an S3 client\n",
    "2. List objects in the baseline results S3 prefix\n",
    "3. Print the names of the generated baseline files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.Session().client(\"s3\")\n",
    "result = s3_client.list_objects(Bucket=bucket, Prefix=baseline_results_prefix)\n",
    "report_files = [report_file.get(\"Key\") for report_file in result.get(\"Contents\")]\n",
    "print(\"Found Files:\")\n",
    "print(\"\\n \".join(report_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Baseline Statistics\n",
    "\n",
    "Retrieve and displays the baseline statistics generated during the baseline creation process.\n",
    "\n",
    "**Actions:**\n",
    "1. Import pandas library for data manipulation\n",
    "2. Get the latest baselining job\n",
    "3. Retrieve the baseline statistics\n",
    "4. Convert the statistics to a pandas DataFrame\n",
    "5. Display the first 10 rows of the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "baseline_job = my_default_monitor.latest_baselining_job\n",
    "schema_df = pd.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Suggested Constraints\n",
    "\n",
    "Retrieve and display the constraints suggested by the model monitor based on the baseline data.\n",
    "\n",
    "**Actions:**\n",
    "1. Retrieve the suggested constraints from the latest baselining job\n",
    "2. Convert the constraints to a pandas DataFrame\n",
    "3. Display the first 10 rows of the constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_df = pd.json_normalize(\n",
    "    baseline_job.suggested_constraints().body_dict[\"features\"]\n",
    ")\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Monitoring Schedule\n",
    "\n",
    "Set up a regular monitoring schedule for the deployed model, using the baseline statistics and constraints.\n",
    "\n",
    "**Actions:**\n",
    "1. Import the CronExpressionGenerator\n",
    "2. Generate a unique name for the monitoring schedule\n",
    "3. Create the monitoring schedule using the default monitor\n",
    "4. Set up hourly monitoring with CloudWatch metrics enabled\n",
    "5. Print the name of the created schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "mon_schedule_name = \"DEMO-xgb-churn-pred-monitor-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "print(\"Creating monitoring schedule...\")\n",
    "my_default_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=mon_schedule_name,\n",
    "    endpoint_input=predictor.endpoint_name,\n",
    "    output_s3_uri=s3_report_path,\n",
    "    statistics=my_default_monitor.baseline_statistics(),\n",
    "    constraints=my_default_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")\n",
    "\n",
    "print(f\"Created monitoring schedule: {mon_schedule_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sample Traffic for Monitoring\n",
    "\n",
    "Generate sample traffic to the endpoint to provide data for the monitoring process.\n",
    "\n",
    "**Actions:**\n",
    "1. Define a function to generate sample traffic\n",
    "2. Open the test dataset file\n",
    "3. Send multiple requests to the endpoint\n",
    "4. Introduce a short delay between requests\n",
    "5. Print confirmation messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def generate_sample_traffic(num_requests=50):\n",
    "    with open(\"test_data/test-dataset-input-cols.csv\", \"r\") as f:\n",
    "        for _ in range(num_requests):\n",
    "            payload = next(f).strip()\n",
    "            response = predictor.predict(payload)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "print(\"Generating sample traffic...\")\n",
    "generate_sample_traffic()\n",
    "print(\"Sample traffic generation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Monitoring Schedule Status\n",
    "\n",
    "Check the status of the monitoring schedule created.\n",
    "\n",
    "**Actions:**\n",
    "1. Set up a loop to check the status multiple times\n",
    "2. Retrieve the current status of the monitoring schedule\n",
    "3. Print the status\n",
    "4. Wait for 30 seconds between checks\n",
    "5. Break the loop if the status is \"Scheduled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):  # Check for up to ~5 minutes\n",
    "    status = my_default_monitor.describe_schedule()[\"MonitoringScheduleStatus\"]\n",
    "    print(f\"Monitoring schedule status: {status}\")\n",
    "    if status == \"Scheduled\":\n",
    "        break\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait for and Check Monitoring Results\n",
    "\n",
    "Wait for the first monitoring execution to complete and then checks the results.\n",
    "\n",
    "**Actions:**\n",
    "1. Wait for an hour to allow the first monitoring execution to run\n",
    "2. List the monitoring executions\n",
    "3. Retrieve the latest execution\n",
    "4. Check the status of the latest execution\n",
    "5. If completed, check for any constraint violations\n",
    "6. Print the results of the monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Waiting for the first execution to complete...\")\n",
    "time.sleep(3600)  # Wait for an hour\n",
    "\n",
    "executions = my_default_monitor.list_executions()\n",
    "if executions:\n",
    "    latest_execution = executions[-1]\n",
    "    execution_status = latest_execution.describe()[\"ProcessingJobStatus\"]\n",
    "    print(f\"Latest execution status: {execution_status}\")\n",
    "    \n",
    "    if execution_status == \"Completed\":\n",
    "        violations = my_default_monitor.latest_monitoring_constraint_violations()\n",
    "        if violations.body_dict[\"violations\"]:\n",
    "            print(\"Violations detected:\")\n",
    "            for violation in violations.body_dict[\"violations\"]:\n",
    "                print(f\"- Feature: {violation['feature_name']}, Type: {violation['constraint_check_type']}\")\n",
    "        else:\n",
    "            print(\"No violations detected.\")\n",
    "else:\n",
    "    print(\"No executions found yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the Monitoring Report URI\n",
    "\n",
    "Retrieve the S3 URI of the monitoring report generated by the latest execution.\n",
    "\n",
    "**Actions:**\n",
    "1. Access the output destination of the latest execution\n",
    "2. Print the report URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_uri = latest_execution.output.destination\n",
    "print(\"Report Uri: {}\".format(report_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Monitoring Report Files\n",
    "\n",
    "List the files generated in the latest monitoring report.\n",
    "\n",
    "**Actions:**\n",
    "1. Import the urlparse function\n",
    "2. Parse the report URI to extract the bucket and key\n",
    "3. Set up an S3 client\n",
    "4. List objects in the report S3 prefix\n",
    "5. Print the names of the report files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "s3uri = urlparse(report_uri)\n",
    "report_bucket = s3uri.netloc\n",
    "report_key = s3uri.path.lstrip(\"/\")\n",
    "print(\"Report bucket: {}\".format(report_bucket))\n",
    "print(\"Report key: {}\".format(report_key))\n",
    "\n",
    "s3_client = boto3.Session().client(\"s3\")\n",
    "result = s3_client.list_objects(Bucket=report_bucket, Prefix=report_key)\n",
    "report_files = [report_file.get(\"Key\") for report_file in result.get(\"Contents\")]\n",
    "print(\"Found Report Files:\")\n",
    "print(\"\\n \".join(report_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Constraint Violations in Detail\n",
    "\n",
    "Retrieves and display detailed information about any constraint violations detected during the monitoring process.\n",
    "\n",
    "**Actions:**\n",
    "1. Set pandas display option to show full column width\n",
    "2. Retrieve the latest monitoring constraint violations\n",
    "3. Convert the violations data to a pandas DataFrame\n",
    "4. Display the first 10 rows of the violations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "violations = my_default_monitor.latest_monitoring_constraint_violations()\n",
    "constraints_df = pd.json_normalize(violations.body_dict[\"violations\"])\n",
    "print(constraints_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Resources\n",
    "\n",
    "Remove the AWS resources created during this notebook to prevent unnecessary charges.\n",
    "\n",
    "**Actions:**\n",
    "1. Delete the Monitoring Schedule in the SageMaker console under \"Governance\"\n",
    "2. Delete the SageMaker Endpoint in the SageMaker console under \"Inference\" > \"Endpoints\"\n",
    "3. Delete the SageMaker Model in the SageMaker console under \"Inference\" > \"Models\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
